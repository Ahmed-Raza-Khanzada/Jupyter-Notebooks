{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "import os\n",
    "from skimage import io,color\n",
    "import cv2\n",
    "import glob\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout,Flatten\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"facial_key_points_distance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_points</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8.06225774829855, 18.027756377319946, 29.8328...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[9.848857801796104, 19.72308292331602, 32.2024...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[9.433981132056603, 19.4164878389476, 30.61045...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[8.94427190999916, 18.867962264113206, 31.4006...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[9.433981132056603, 19.4164878389476, 31.40063...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          key_points Labels\n",
       "0  [8.06225774829855, 18.027756377319946, 29.8328...  happy\n",
       "1  [9.848857801796104, 19.72308292331602, 32.2024...  happy\n",
       "2  [9.433981132056603, 19.4164878389476, 30.61045...  happy\n",
       "3  [8.94427190999916, 18.867962264113206, 31.4006...  happy\n",
       "4  [9.433981132056603, 19.4164878389476, 31.40063...  happy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_points</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8.06225774829855, 18.027756377319946, 29.8328...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[9.848857801796104, 19.72308292331602, 32.2024...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[9.433981132056603, 19.4164878389476, 30.61045...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[8.94427190999916, 18.867962264113206, 31.4006...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[9.433981132056603, 19.4164878389476, 31.40063...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          key_points Labels\n",
       "0  [8.06225774829855, 18.027756377319946, 29.8328...  happy\n",
       "1  [9.848857801796104, 19.72308292331602, 32.2024...  happy\n",
       "2  [9.433981132056603, 19.4164878389476, 30.61045...  happy\n",
       "3  [8.94427190999916, 18.867962264113206, 31.4006...  happy\n",
       "4  [9.433981132056603, 19.4164878389476, 31.40063...  happy"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.key_points = df.key_points.apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_points</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8.06225774829855, 18.027756377319946, 29.8328...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[9.848857801796104, 19.72308292331602, 32.2024...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[9.433981132056603, 19.4164878389476, 30.61045...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[8.94427190999916, 18.867962264113206, 31.4006...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[9.433981132056603, 19.4164878389476, 31.40063...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          key_points Labels\n",
       "0  [8.06225774829855, 18.027756377319946, 29.8328...  happy\n",
       "1  [9.848857801796104, 19.72308292331602, 32.2024...  happy\n",
       "2  [9.433981132056603, 19.4164878389476, 30.61045...  happy\n",
       "3  [8.94427190999916, 18.867962264113206, 31.4006...  happy\n",
       "4  [9.433981132056603, 19.4164878389476, 31.40063...  happy"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(df[\"key_points\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 12432)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.stack(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.06225775,  18.02775638,  29.83286778, ..., 113.53413584,\n",
       "         97.12878049, 131.18688959],\n",
       "       [  9.8488578 ,  19.72308292,  32.20248438, ..., 113.53413584,\n",
       "         96.13012015, 131.13733259],\n",
       "       [  9.43398113,  19.41648784,  30.61045573, ..., 113.53413584,\n",
       "         96.13012015, 131.09538512],\n",
       "       ...,\n",
       "       [  5.        ,  10.        ,  18.02775638, ..., 103.5857133 ,\n",
       "         88.09086218, 120.26637103],\n",
       "       [  4.24264069,  10.        ,  17.20465053, ..., 103.48429833,\n",
       "         88.141931  , 121.20231021],\n",
       "       [  3.60555128,   8.60232527,  16.64331698, ..., 104.58011283,\n",
       "         88.09086218, 121.26417443]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df[\"Labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data/data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "labels = to_categorical(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12432,) (3000, 12432)\n",
      "(3000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data[0].shape,data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_distance(x1,y1,x2,y2):\n",
    "    dist = math.sqrt((x2-x1)**2+(y2-y1)**2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data,labels,shuffle=True,test_size = 0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0.00005,\n",
    "    patience=22,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "callbacks = [\n",
    "    early_stopping\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.optimizers import SGD\n",
    "#sgd = SGD(lr = 0.01,momentum = 0.9,nesterov = True)\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(1020,activation= \"relu\",input_shape= (12432,)))\n",
    "model.add(layers.Dense(900,activation = \"relu\"))\n",
    "model.add(layers.Dense(800,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(layers.Dense(700,activation=\"relu\"))\n",
    "model.add(layers.Dense(3,activation=\"softmax\"))\n",
    "model.compile(optimizer = \"adam\" ,loss = \"categorical_crossentropy\" , metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Dense(1020,activation= \"relu\",input_shape= (12432,)))\n",
    "model.add(layers.Dense(900,activation = \"relu\"))\n",
    "model.add(layers.Dense(800,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(layers.Dense(700,activation=\"relu\"))\n",
    "model.add(layers.Dense(3,activation=\"softmax\"))\n",
    "model.compile(optimizer = \"adam\" ,loss = \"categorical_crossentropy\" , metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "49/49 [==============================] - 6s 130ms/step - loss: 1.7364 - accuracy: 0.4041 - val_loss: 0.8324 - val_accuracy: 0.6519\n",
      "Epoch 2/40\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 0.6588 - accuracy: 0.6045 - val_loss: 0.4966 - val_accuracy: 0.6815\n",
      "Epoch 3/40\n",
      "49/49 [==============================] - 5s 112ms/step - loss: 0.4859 - accuracy: 0.6901 - val_loss: 0.6224 - val_accuracy: 0.5852\n",
      "Epoch 4/40\n",
      "49/49 [==============================] - 6s 112ms/step - loss: 1.1386 - accuracy: 0.5148 - val_loss: 0.8401 - val_accuracy: 0.6222\n",
      "Epoch 5/40\n",
      "49/49 [==============================] - 6s 117ms/step - loss: 1.0470 - accuracy: 0.5165 - val_loss: 1.1969 - val_accuracy: 0.2778\n",
      "Epoch 6/40\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 0.7917 - accuracy: 0.6267 - val_loss: 0.6636 - val_accuracy: 0.6259\n",
      "Epoch 7/40\n",
      "49/49 [==============================] - 6s 117ms/step - loss: 0.5600 - accuracy: 0.6827 - val_loss: 0.5238 - val_accuracy: 0.6519\n",
      "Epoch 8/40\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 0.4823 - accuracy: 0.6700 - val_loss: 0.5050 - val_accuracy: 0.6444\n",
      "Epoch 9/40\n",
      "49/49 [==============================] - 6s 119ms/step - loss: 0.4762 - accuracy: 0.6613 - val_loss: 0.5024 - val_accuracy: 0.6556\n",
      "Epoch 10/40\n",
      "49/49 [==============================] - 6s 116ms/step - loss: 0.4686 - accuracy: 0.6811 - val_loss: 0.4974 - val_accuracy: 0.7444\n",
      "Epoch 11/40\n",
      "49/49 [==============================] - 6s 125ms/step - loss: 0.4640 - accuracy: 0.6852 - val_loss: 0.4979 - val_accuracy: 0.6630\n",
      "Epoch 12/40\n",
      "49/49 [==============================] - 6s 127ms/step - loss: 0.4652 - accuracy: 0.6877 - val_loss: 0.5062 - val_accuracy: 0.6222\n",
      "Epoch 13/40\n",
      "49/49 [==============================] - 6s 130ms/step - loss: 1.3087 - accuracy: 0.5148 - val_loss: 1.1076 - val_accuracy: 0.3741\n",
      "Epoch 14/40\n",
      "49/49 [==============================] - 7s 134ms/step - loss: 1.1217 - accuracy: 0.3280 - val_loss: 1.0989 - val_accuracy: 0.3481\n",
      "Epoch 15/40\n",
      "49/49 [==============================] - 6s 121ms/step - loss: 1.0993 - accuracy: 0.3288 - val_loss: 1.1004 - val_accuracy: 0.2778\n",
      "Epoch 16/40\n",
      "49/49 [==============================] - 6s 122ms/step - loss: 1.0995 - accuracy: 0.3366 - val_loss: 1.1012 - val_accuracy: 0.2778\n",
      "Epoch 17/40\n",
      "49/49 [==============================] - 6s 115ms/step - loss: 1.0993 - accuracy: 0.3407 - val_loss: 1.0988 - val_accuracy: 0.3481\n",
      "Epoch 18/40\n",
      "49/49 [==============================] - 6s 120ms/step - loss: 1.1007 - accuracy: 0.3288 - val_loss: 1.1002 - val_accuracy: 0.2778\n",
      "Epoch 19/40\n",
      "49/49 [==============================] - 6s 117ms/step - loss: 1.0996 - accuracy: 0.3457 - val_loss: 1.1019 - val_accuracy: 0.2778\n",
      "Epoch 20/40\n",
      "49/49 [==============================] - 6s 126ms/step - loss: 1.1001 - accuracy: 0.3292 - val_loss: 1.0994 - val_accuracy: 0.3481\n",
      "Epoch 21/40\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 1.0995 - accuracy: 0.3329 - val_loss: 1.0999 - val_accuracy: 0.2778\n",
      "Epoch 22/40\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 1.0990 - accuracy: 0.3189 - val_loss: 1.0986 - val_accuracy: 0.3481\n",
      "Epoch 23/40\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 1.0993 - accuracy: 0.3387 - val_loss: 1.0991 - val_accuracy: 0.3481\n",
      "Epoch 24/40\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 1.0995 - accuracy: 0.3346 - val_loss: 1.0988 - val_accuracy: 0.3481\n",
      "Epoch 25/40\n",
      "49/49 [==============================] - 6s 113ms/step - loss: 1.0998 - accuracy: 0.3296 - val_loss: 1.1001 - val_accuracy: 0.2778\n",
      "Epoch 26/40\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 1.0992 - accuracy: 0.3366 - val_loss: 1.1001 - val_accuracy: 0.2778\n",
      "Epoch 27/40\n",
      "49/49 [==============================] - 6s 114ms/step - loss: 1.0983 - accuracy: 0.3267 - val_loss: 1.0996 - val_accuracy: 0.2778\n",
      "Epoch 28/40\n",
      "49/49 [==============================] - 6s 116ms/step - loss: 1.0994 - accuracy: 0.3263 - val_loss: 1.0999 - val_accuracy: 0.2778\n",
      "Epoch 29/40\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 1.0985 - accuracy: 0.3407 - val_loss: 1.1005 - val_accuracy: 0.2778\n",
      "Epoch 30/40\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 1.0990 - accuracy: 0.3420 - val_loss: 1.0995 - val_accuracy: 0.3481\n",
      "Epoch 31/40\n",
      "49/49 [==============================] - 6s 118ms/step - loss: 1.0982 - accuracy: 0.3407 - val_loss: 1.1010 - val_accuracy: 0.2778\n",
      "Epoch 32/40\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.0983 - accuracy: 0.3473Restoring model weights from the end of the best epoch.\n",
      "49/49 [==============================] - 6s 121ms/step - loss: 1.0983 - accuracy: 0.3473 - val_loss: 1.0995 - val_accuracy: 0.3481\n",
      "Epoch 00032: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,batch_size = 50,epochs = 40,validation_split=0.1,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Using ANN                         \n",
      "loss on testing is 0.4431024193763733\n",
      "accuracy on testing is 0.7300000190734863\n"
     ]
    }
   ],
   "source": [
    "loss,acc = model.evaluate(x_test,y_test,verbose = 0)\n",
    "print(\"               Using ANN                         \")\n",
    "print(f\"loss on testing is {loss}\\naccuracy on testing is {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"facial_key_points_model4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"facial_key_points_distance.csv\")\n",
    "df = df.drop(\"Unnamed: 0\",axis=1)\n",
    "labels = np.array(df[\"Labels\"])\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"facial_key_points_model4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n",
      "Ignoring empty camera frame.\n"
     ]
    }
   ],
   "source": [
    "# For webcam input:\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "      success, image = cap.read()\n",
    "      if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        # If loading a video, use 'break' instead of 'continue'.\n",
    "        continue\n",
    "\n",
    "      # Flip the image horizontally for a later selfie-view display, and convert\n",
    "      # the BGR image to RGB.\n",
    "      image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "      # To improve performance, optionally mark the image as not writeable to\n",
    "      # pass by reference.\n",
    "      image.flags.writeable = False\n",
    "      results = face_mesh.process(image)\n",
    "\n",
    "      # Draw landmark annotation on the image.\n",
    "      image.flags.writeable = True\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "      if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "          a =mp_drawing.draw_landmarks(\n",
    "                image=image,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACE_CONNECTIONS,\n",
    "                landmark_drawing_spec=drawing_spec,\n",
    "                connection_drawing_spec=drawing_spec)\n",
    "          b= []\n",
    "          for pos,i in enumerate(a):\n",
    "              for pos1,j in enumerate(a):\n",
    "                  if pos!=pos1:\n",
    "                      x1,y1 = i\n",
    "                      x2,y2 = j\n",
    "                      b.append(cal_distance(x1,y1,x2,y2))\n",
    "          if len(b)==12432:\n",
    "              b = np.array(b)\n",
    "              b = b/b.max()\n",
    "              pred = model.predict(b.reshape(1,12432))\n",
    "              pred = np.argmax(pred,axis=1)\n",
    "              pred = encoder.inverse_transform(pred)\n",
    "              if pred[0]==\"happy\":\n",
    "                 color=(0, 255, 0)\n",
    "              elif pred[0]==\"sad\":\n",
    "                 color=(0, 0, 255)\n",
    "              elif pred[0]==\"neutral\":\n",
    "                 color=(0, 255, 255)\n",
    "              cv2.putText(image,  \n",
    "                pred[0],  \n",
    "                (50, 50),  \n",
    "                 cv2.FONT_HERSHEY_SIMPLEX , 2,  \n",
    "                color,  \n",
    "                2,  \n",
    "                cv2.LINE_4) \n",
    "      cv2.imshow('MediaPipe FaceMesh', image)\n",
    "      if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "face_mesh.close()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= [(1,2),(4,5)]\n",
    "b= [j for i in a for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(936,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:976 __call__\n        self.name)\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer sequential_4 is incompatible with the layer: expected axis -1 of input shape to have value 936 but received input with shape [None, 1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-bcbaa9d3be39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3141\u001b[0m     graph_function = self._create_graph_function(\n\u001b[1;32m-> 3142\u001b[1;33m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[0;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:976 __call__\n        self.name)\n    C:\\Users\\HP\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer sequential_4 is incompatible with the layer: expected axis -1 of input shape to have value 936 but received input with shape [None, 1]\n"
     ]
    }
   ],
   "source": [
    "a =[]\n",
    "for i in range(0,936):\n",
    "  a. append(i)\n",
    "a = np.array(a)\n",
    "a = a/a.max()\n",
    "print(a.shape)\n",
    "print(model.predict(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape () instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-0f15a61ee2bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m  \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \"\"\"\n\u001b[0;32m    152\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         \u001b[1;31m# inverse transform of empty array is empty array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    864\u001b[0m     raise ValueError(\n\u001b[0;32m    865\u001b[0m         \u001b[1;34m\"y should be a 1d array, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m         \"got an array of shape {} instead.\".format(shape))\n\u001b[0m\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape () instead."
     ]
    }
   ],
   "source": [
    "# p = model.predict(x_test[0].reshape(1,936))\n",
    "# p = np.argmax(p,axis=1)\n",
    "# p=  encoder.inverse_transform(p)\n",
    "# l = np.argmax(y_test[0])\n",
    "# l = encoder.inverse_transform(l)\n",
    "# print(p,l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d25f48e861da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
     ]
    }
   ],
   "source": [
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'videoCapture'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-799988cf470c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'videoCapture'"
     ]
    }
   ],
   "source": [
    "cap = cv2.videoCapture(0)\n",
    "while cap.isOpened():\n",
    "    success,image= cap.read()\n",
    "    if not success:\n",
    "        continue\n",
    "    image = cv2.cvtColor(cv2.flip(image,1),cv2.COLOR_BGR2GRAY)\n",
    "    rects =  detector(image,0)\n",
    "    for rect in rects:\n",
    "        shape = predictor(image,rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        for (x,y) in shape:\n",
    "            cv2.circle(image,(x,y),1,(0,0,255),-1)\n",
    "        cv2.imshow(\"Frame\",image)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key== ord(\"q\"):\n",
    "            break\n",
    "cv2.destroyAllWindows()\n",
    "cap.stop()    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-c93c7d5515f3>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-c93c7d5515f3>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    for (x,y)\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "image  = cv2cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "rects = detector(image,0)\n",
    "for rect in rects:\n",
    "    shape = predictor(image,rect)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "    for (x,y) in shape:\n",
    "        cv2.circle(image,(x,y),1,(0,0,255),-1)\n",
    "    cv2.imshow(\"Frame\",image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
