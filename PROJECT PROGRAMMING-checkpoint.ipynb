{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dir1):\n",
    "    import glob\n",
    "    import os\n",
    "    import cv2\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from tensorflow.keras.models import load_model\n",
    "    import matplotlib.pyplot as plt\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    y = pd.read_csv(\"E:/asl/asl_alphabet_test/asl_alphabet_train/asl_label.csv\",header = None)\n",
    "    y = np.array(y)\n",
    "    y = y.reshape(y.shape[1])\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(y)\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    y = to_categorical(y)\n",
    "    img_dir = dir1 # Enter Directory of all images \n",
    "    data_path = os.path.join(img_dir,'*g')\n",
    "    files = glob.glob(data_path)\n",
    "    x = []\n",
    "    for f1 in files:\n",
    "        img = cv2.imread(f1,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (64,64))\n",
    "        x.append(img)\n",
    "    x = np.array(x)\n",
    "    plt.imshow(x[0])\n",
    "    plt.show()\n",
    "    x = x.astype(\"float\")/255\n",
    "    x = x.reshape(x.shape[0],64,64,1)\n",
    "    model = load_model(\"programming_project_model.h5\")\n",
    "    pred = model.predict(x)\n",
    "    pred_dummy1 = np.argmax(pred,axis=1)\n",
    "    pred_dummy2 = encoder.inverse_transform(pred_dummy1)\n",
    "    print(f\"predicted dummy images are {pred_dummy2} \")\n",
    "    j = 221\n",
    "    print(\"The Label above images is not provided its predicted by our model\")\n",
    "    for i,v in zip(range(len(x)),pred_dummy2):\n",
    "        plt.subplot(j)\n",
    "        plt.title(str(v))\n",
    "        plt.imshow(x[i], cmap=plt.get_cmap('gray'))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted dummy images are ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'L' 'I' 'J' 'K' 'L' 'M' 'nothing' 'N' 'O'\n",
      " 'P' 'Q' 'R' 'space' 'S' 'T' 'U' 'V' 'W'] \n",
      "The Label above images is not provided its predicted by our model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directory = \"C:/Users/HP/Desktop/New folder\" \n",
    "predict(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(img_path,model):\n",
    "    import glob\n",
    "    import os\n",
    "    import cv2\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from tensorflow.keras.models import load_model\n",
    "    import matplotlib.pyplot as plt\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "    y = pd.read_csv(\"E:/asl/asl_alphabet_test/asl_alphabet_train/asl_label.csv\",header = None)\n",
    "    y = np.array(y)\n",
    "    y = y.reshape(y.shape[1])\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(y)\n",
    "\n",
    "    y = to_categorical(y)\n",
    "    img = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n",
    "    img =  cv2.resize(img, (64,64))\n",
    "    x = np.array(img) \n",
    "    x = x.astype(\"float\")/255\n",
    "    x = x.reshape(1,64,64,1)\n",
    "    model = load_model(\"programming_project_model.h5\")\n",
    "    pred = model.predict(x)\n",
    "    pred_dummy1 = np.argmax(pred,axis=1)\n",
    "    pred_dummy2 = encoder.inverse_transform(pred_dummy1)\n",
    "    return pred_dummy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(img_path,model):\n",
    "\n",
    "    y = pd.read_csv(\"E:/asl/asl_alphabet_test/asl_alphabet_train/asl_label.csv\",header = None)\n",
    "    y = np.array(y)\n",
    "    y = y.reshape(y.shape[1])\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(y)\n",
    "\n",
    "    y = to_categorical(y)\n",
    "    img = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n",
    "    img =  cv2.resize(img, (64,64))\n",
    "    x = np.array(img) \n",
    "    x = x.astype(\"float\")/255\n",
    "    x = x.reshape(1,64,64,1)\n",
    "    model = load_model(\"programming_project_model.h5\")\n",
    "    pred = model.predict(x)\n",
    "    pred_dummy1 = np.argmax(pred,axis=1)\n",
    "    pred_dummy2 = encoder.inverse_transform(pred_dummy1)\n",
    "    return pred_dummy2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
